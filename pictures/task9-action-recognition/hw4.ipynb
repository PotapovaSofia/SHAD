{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import imageio\n",
    "from skimage import transform\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from queue import Queue\n",
    "from random import randint, shuffle\n",
    "import threading\n",
    "from time import time\n",
    "from itertools import chain\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.layers import BatchNormLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import ElemwiseSumLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "\n",
    "\n",
    "def build_simple_block(incoming_layer, names,\n",
    "                       num_filters, filter_size, stride, pad,\n",
    "                       use_bias=False, nonlin=rectify):\n",
    "    \"\"\"Creates stacked Lasagne layers ConvLayer -> BN -> (ReLu)\n",
    "    Parameters:\n",
    "    ----------\n",
    "    incoming_layer : instance of Lasagne layer\n",
    "        Parent layer\n",
    "    names : list of string\n",
    "        Names of the layers in block\n",
    "    num_filters : int\n",
    "        Number of filters in convolution layer\n",
    "    filter_size : int\n",
    "        Size of filters in convolution layer\n",
    "    stride : int\n",
    "        Stride of convolution layer\n",
    "    pad : int\n",
    "        Padding of convolution layer\n",
    "    use_bias : bool\n",
    "        Whether to use bias in conlovution layer\n",
    "    nonlin : function\n",
    "        Nonlinearity type of Nonlinearity layer\n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (net, last_layer_name)\n",
    "        net : dict\n",
    "            Dictionary with stacked layers\n",
    "        last_layer_name : string\n",
    "            Last layer name\n",
    "    \"\"\"\n",
    "    names = list(names)\n",
    "    net = []\n",
    "    net.append((\n",
    "            names[0],\n",
    "            ConvLayer(incoming_layer, num_filters, filter_size, stride, pad,\n",
    "                      nonlinearity=None) if use_bias\n",
    "            else ConvLayer(incoming_layer, num_filters, filter_size, stride, pad, b=None,\n",
    "                           nonlinearity=None)\n",
    "        ))\n",
    "\n",
    "    net.append((\n",
    "            names[1],\n",
    "            BatchNormLayer(net[-1][1])\n",
    "        ))\n",
    "    if nonlin is not None:\n",
    "        net.append((\n",
    "            names[2],\n",
    "            NonlinearityLayer(net[-1][1], nonlinearity=nonlin)\n",
    "        ))\n",
    "\n",
    "    return dict(net), net[-1][0]\n",
    "\n",
    "\n",
    "def build_residual_block(incoming_layer, ratio_n_filter=1.0, ratio_size=1.0, has_left_branch=False,\n",
    "                         upscale_factor=4, ix=''):\n",
    "    \"\"\"Creates two-branch residual block\n",
    "    Parameters:\n",
    "    ----------\n",
    "    incoming_layer : instance of Lasagne layer\n",
    "        Parent layer\n",
    "    ratio_n_filter : float\n",
    "        Scale factor of filter bank at the input of residual block\n",
    "    ratio_size : float\n",
    "        Scale factor of filter size\n",
    "    has_left_branch : bool\n",
    "        if True, then left branch contains simple block\n",
    "    upscale_factor : float\n",
    "        Scale factor of filter bank at the output of residual block\n",
    "    ix : int\n",
    "        Id of residual block\n",
    "    Returns\n",
    "    -------\n",
    "    tuple: (net, last_layer_name)\n",
    "        net : dict\n",
    "            Dictionary with stacked layers\n",
    "        last_layer_name : string\n",
    "            Last layer name\n",
    "    \"\"\"\n",
    "    simple_block_name_pattern = ['res%s_branch%i%s', 'bn%s_branch%i%s', 'res%s_branch%i%s_relu']\n",
    "\n",
    "    net = {}\n",
    "\n",
    "    # right branch\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        incoming_layer, map(lambda s: s % (ix, 2, 'a'), simple_block_name_pattern),\n",
    "        int(lasagne.layers.get_output_shape(incoming_layer)[1]*ratio_n_filter), 1, int(1.0/ratio_size), 0)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'b'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1], 3, 1, 1)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    net_tmp, last_layer_name = build_simple_block(\n",
    "        net[last_layer_name], map(lambda s: s % (ix, 2, 'c'), simple_block_name_pattern),\n",
    "        lasagne.layers.get_output_shape(net[last_layer_name])[1]*upscale_factor, 1, 1, 0,\n",
    "        nonlin=None)\n",
    "    net.update(net_tmp)\n",
    "\n",
    "    right_tail = net[last_layer_name]\n",
    "    left_tail = incoming_layer\n",
    "\n",
    "    # left branch\n",
    "    if has_left_branch:\n",
    "        net_tmp, last_layer_name = build_simple_block(\n",
    "            incoming_layer, map(lambda s: s % (ix, 1, ''), simple_block_name_pattern),\n",
    "            int(lasagne.layers.get_output_shape(incoming_layer)[1]*4*ratio_n_filter), 1, int(1.0/ratio_size), 0,\n",
    "            nonlin=None)\n",
    "        net.update(net_tmp)\n",
    "        left_tail = net[last_layer_name]\n",
    "\n",
    "    net['res%s' % ix] = ElemwiseSumLayer([left_tail, right_tail], coeffs=1)\n",
    "    net['res%s_relu' % ix] = NonlinearityLayer(net['res%s' % ix], nonlinearity=rectify)\n",
    "\n",
    "    return net, 'res%s_relu' % ix\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    sub_net, parent_layer_name = build_simple_block(\n",
    "        net['input'], ['conv1', 'bn_conv1', 'conv1_relu'],\n",
    "        64, 7, 2, 3, use_bias=True)\n",
    "    net.update(sub_net)\n",
    "    net['pool1'] = PoolLayer(net[parent_layer_name], pool_size=3, stride=2, pad=0, mode='max', ignore_border=False)\n",
    "    block_size = list('abc')\n",
    "    parent_layer_name = 'pool1'\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1, 1, True, 4, ix='2%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='2%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcd')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='3%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='3%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abcdef')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='4%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='4%s' % c)\n",
    "        net.update(sub_net)\n",
    "\n",
    "    block_size = list('abc')\n",
    "    for c in block_size:\n",
    "        if c == 'a':\n",
    "            sub_net, parent_layer_name = build_residual_block(\n",
    "                net[parent_layer_name], 1.0/2, 1.0/2, True, 4, ix='5%s' % c)\n",
    "        else:\n",
    "            sub_net, parent_layer_name = build_residual_block(net[parent_layer_name], 1.0/4, 1, False, 4, ix='5%s' % c)\n",
    "        net.update(sub_net)\n",
    "    net['pool5'] = PoolLayer(net[parent_layer_name], pool_size=7, stride=1, pad=0,\n",
    "                             mode='average_exc_pad', ignore_border=False)\n",
    "    net['fc1000'] = DenseLayer(net['pool5'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc1000'], nonlinearity=softmax)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "resnet = pickle.load(open('resnet50.pkl', 'rb'), encoding='latin1')\n",
    "lasagne.layers.set_all_param_values(model['prob'], resnet['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model1 = {}\n",
    "model1['dense1'] = DenseLayer(model['pool5'], 500)\n",
    "model1['dense2'] = DenseLayer(model1['dense1'], 500)\n",
    "model1['final'] = DenseLayer(model1['dense2'], 101, nonlinearity=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_params = []\n",
    "for v in model1.values():\n",
    "    all_params += v.get_params(trainable=True)\n",
    "for k, v in model.items():\n",
    "    if k.startswith('res5'):\n",
    "        all_params += v.get_params(trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net_in = T.tensor4()\n",
    "net_trg = T.ivector()\n",
    "net_out = T.matrix()\n",
    "\n",
    "pred = lasagne.layers.get_output(model1['final'], net_in)\n",
    "pred_det = lasagne.layers.get_output(model1['final'], net_in, deterministic=True)\n",
    "\n",
    "acc = lasagne.objectives.categorical_accuracy(pred_det, net_trg).mean()\n",
    "loss = lasagne.objectives.categorical_crossentropy(pred, net_trg).mean()\n",
    "\n",
    "updates = lasagne.updates.adam(loss, all_params, learning_rate=0.0015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = theano.function([net_in, net_trg], loss, updates=updates)\n",
    "val = theano.function([net_in, net_trg], acc)\n",
    "pred = theano.function([net_in], pred_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def iter_data(dir_name, mask, frames_cnt=5, imsize=(200, 200), df=None):\n",
    "    for file_name in glob(os.path.join(dir_name, mask)):\n",
    "        name = os.path.split(file_name)[-1]\n",
    "        if df is not None:\n",
    "            name = df[df.filename==name].classnum.values[0]\n",
    "        with imageio.get_reader(file_name) as reader:\n",
    "            length = reader.get_length()\n",
    "            for i in range(frames_cnt):\n",
    "                frame = reader.get_data(randint(0, length - 1))\n",
    "                frame = transform.resize(frame, imsize, mode='constant')\n",
    "                frame = frame.swapaxes(2, 1).swapaxes(1, 0)\n",
    "                yield (frame, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_gt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "iter_train = iter_data('action-recognition-train', '[0-7]*.avi', frames_cnt=1, df=train_df)\n",
    "iter_val = iter_data('action-recognition-train', '8*.avi', frames_cnt=1, df=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def iter_batches(data, size):\n",
    "    bx, by = [], []\n",
    "    for x, y in data:\n",
    "        bx.append(x)\n",
    "        by.append(y)\n",
    "        if len(bx) == size:\n",
    "            yield (np.array(bx, dtype=np.float32), by)\n",
    "            bx, by = [], []\n",
    "    if len(by):\n",
    "        yield (np.array(bx, dtype=np.float32), by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [02:45, 165.68s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4fbac989d9b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0merr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    start = time()\n",
    "    \n",
    "    err, cnt = 0., 0\n",
    "    for x, y in tqdm(iter_batches(iter_train, size=200)):\n",
    "        err += train(x, y)\n",
    "        cnt += 1\n",
    "    train_err = err / cnt\n",
    "\n",
    "    err, cnt = 0., 0\n",
    "    for x, y in tqdm(iter_batches(iter_val, size=200)):\n",
    "        err += val(bx, by)\n",
    "        batches += 1\n",
    "    val_err = err / cnt\n",
    "\n",
    "    end = time()\n",
    "    print('epoch: {} [time: {}] train loss: {}, val loss: {}'.format(i, end - start, train_err, val_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FRAMES_CNT = 3\n",
    "iter_test = iter_data('action-recognition-test', '*.avi', frames_cnt=FRAMES_CNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for x, y in tqdm(iter_batches(iter_test, size=200)):\n",
    "    res = pred(x)\n",
    "    res = res.reshape([-1, FRAMES_CNT, 101])\n",
    "    res = res.mean(axis=1).argmax(axis=1)\n",
    "    for file_name, res in zip(y[::FRAMES_CNT], res):\n",
    "        results[file_name] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result_file = open('result.csv', 'w')\n",
    "result_file.write('filename,classnum\\n')\n",
    "for file_name, class_label in results.items():\n",
    "    result_file.write('{},{}\\n'.format(file_name, class_label))\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
